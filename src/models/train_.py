from lifelines import KaplanMeierFitter
import numpy as np
import pandas as pd
from lifelines import NelsonAalenFitter
import warnings
import pandas as pd
from sksurv.ensemble import RandomSurvivalForest
from sksurv.metrics import concordance_index_censored
from sksurv.util import Surv

warnings.filterwarnings("ignore", category=UserWarning)

DATA_PATH = "../../data/processed/lendingclub_features_for_rf.parquet"
FEATURE_PATH = "../../data/processed/features_final_list_rf.csv"

# --------------------------------------------------
# 1) ë°ì´í„° ë¡œë“œ & í•„í„°
# --------------------------------------------------
df = pd.read_parquet(DATA_PATH)
df["issue_d"] = pd.to_datetime(df["issue_d"], errors="coerce")
df["last_pymnt_d"] = pd.to_datetime(df["last_pymnt_d"], errors="coerce")

# â–¼â–¼â–¼ ì¶”ê°€ ì½”ë“œ â–¼â–¼â–¼  
print(f"issue_d NaT ê°œìˆ˜: {df['issue_d'].isna().sum()}")
print(f"last_pymnt_d NaT ê°œìˆ˜: {df['last_pymnt_d'].isna().sum()}")
df = df[df['issue_d'].notna() & df['last_pymnt_d'].notna()]  # NaT ì œê±°


# --------------------------------------------------
# COVIDâ€‘19 ë…¸ì¶œ ë³€ìˆ˜ ì •ì˜
#   - cutâ€‘off ë‚ ì§œ : 2020â€‘03â€‘01
#   - ë¹„â€‘ë¶€ë„(Charged Off/Default ì•„ë‹˜) ëŒ€ì¶œ  â†’  issue_d + term â‰¤ cutâ€‘off
#   - ë¶€ë„ ëŒ€ì¶œ                              â†’  last_pymnt_d â‰¤ cutâ€‘off
# --------------------------------------------------
cutoff = pd.to_datetime("2020-03-01")

# termì´ '36 months' ê°™ì€ ë¬¸ìì—´ì´ë©´ ìˆ«ì(ì›”ìˆ˜)ë§Œ ì¶”ì¶œ
df["term"] = (
    df["term"].astype(str)
      .str.extract(r"(\d+)")[0]
      .astype(int)
)

# ë§Œê¸°ì¼ = issue_d + term_m Ã— 30ì¼ (ì›” ë‹¨ìœ„ ê·¼ì‚¬)
df["maturity_d"] = df["issue_d"] + pd.to_timedelta(df["term"] * 30, unit="D")

# ë¶€ë„(event==1)  â†’  ë§ˆì§€ë§‰ ìƒí™˜ì¼ì´ cutoff **ì´ì „(í¬í•¨)** ì´ë©´ ì½”ë¡œë‚˜ ë…¸ì¶œ
# ê·¸ ì™¸            â†’  ë§Œê¸°ì¼ì´ cutoff **ì´ì „(í¬í•¨)** ì´ë©´ ì½”ë¡œë‚˜ ë…¸ì¶œ
df["covid_exposure"] = np.where(
    df["E"] == 1,
    df["last_pymnt_d"] >= cutoff,
    df["maturity_d"]   >= cutoff
).astype(int)

# Calculate survival duration:
# If event occurred (event == 1), use duration until event (e.g. charged off)
# Else, use duration until end of observation (censored)
# T / event ê²°ì¸¡ & ìŒìˆ˜ ì œê±°
df = df.dropna(subset=["T", "E"])
df = df[df["T"] >= 0]

# --------------------------------------------------
# 2) íŠ¹ì§• í–‰ë ¬ / íƒ€ê¹ƒ
# --------------------------------------------------
features = pd.read_csv(FEATURE_PATH)["feature"].tolist()
features = [f for f in features if f in df.columns]

exclude_types = ["object", "datetime64[ns]"]
features = [col for col in features if str(df[col].dtype) not in exclude_types]

X = df[features]

# â–¼â–¼â–¼ ì¶”ê°€ ì½”ë“œ â–¼â–¼â–¼  
print("â–¶ ë°ì´í„° ë¶„í¬ í™•ì¸:")
print(f"- ì „ì²´ ë°ì´í„°: {len(df)}")
print(f"- COVID ë…¸ì¶œ ê·¸ë£¹: {df['covid_exposure'].sum()}")
print(f"- issue_d < cutoff: {(df['issue_d'] < cutoff).sum()}")
print(f"- ìµœì†Œ issue_d: {df['issue_d'].min()}, ìµœëŒ€ issue_d: {df['issue_d'].max()}")

df = df[df['covid_exposure'] == 1]
X = df[features].copy()

# --------------------------------------------------
# 3) ì‹œê°„ìˆœ ë¶„í• 
# --------------------------------------------------
# í›ˆë ¨ ë°ì´í„° ì¸ë±ìŠ¤ ë§ˆìŠ¤í¬: issue_d < cutoff & covid_exposure == 0
train_mask = (df['issue_d'] < cutoff).reindex(X.index).fillna(False)

# Debug: inspect mask components
print(f"â–¶ Total rows: {len(df)}")
print(f"â–¶ Rows with issue_d < cutoff ({cutoff.date()}): {int((df['issue_d'] < cutoff).sum())}")

# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test = X.loc[train_mask], X.loc[~train_mask]
y_train = df.loc[train_mask, ["T", "E"]]
y_test  = df.loc[~train_mask, ["T", "E"]]
print(X_train.dtypes.value_counts()) # category íƒ€ì…ê³¼ ìˆ«ìí˜•(int/float)ë§Œ ì¡´ì¬í•´ì•¼ í•¨


# Fallback if no training data with covid_exposure == 0
if X_train.shape[0] == 0:
    print("âš ï¸ No non-exposed training data; using time-based split only.")
    train_mask = df["issue_d"] < cutoff
    X_train, X_test = X.loc[train_mask], X.loc[~train_mask]
    y_train = df.loc[train_mask, ["T", "E"]]
    y_test  = df.loc[~train_mask, ["T", "E"]]

# --------------------------------------------------
# 4) Nelson-Aalen ê¸°ë°˜ Hazard Rate ì¶”ì •
# --------------------------------------------------
naf = NelsonAalenFitter()
df["issue_month"] = df["issue_d"].dt.to_period("M")
monthly_hazards = {}

for month, group_df in df.groupby("issue_month"):
    if len(group_df) < 100:
        continue
    try:
        naf.fit(group_df["T"], event_observed=group_df["E"])
        cum_hazard = naf.cumulative_hazard_
        # ìˆœê°„ hazard â‰ˆ ëˆ„ì  hazard ì°¨ë¶„
        inst_hazard = cum_hazard.diff().fillna(0)
        monthly_hazards[str(month)] = inst_hazard.mean().values[0]
    except Exception as e:
        print(f"âš ï¸ {month} ì›” hazard ê³„ì‚° ì˜¤ë¥˜: {e}")
        continue

# hazard í‰ê· ê°’ ì‹œê³„ì—´ ì‹œê°í™”
import matplotlib.pyplot as plt
plt.figure(figsize=(12, 5))
plt.plot(monthly_hazards.keys(), monthly_hazards.values(), marker="o", label="NA estimated hazard")
plt.title("Monthly Nelson-Aalen estimated Hazard Rate")
plt.xlabel("issued month")
plt.ylabel("avg Hazard")
plt.xticks(rotation=45)
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()
print("âœ… NA ê¸°ë°˜ ì›”ë³„ hazard ì¶”ì • ì™„ë£Œ")

# --------------------------------------------------
# 5) Random Survival Forest ëª¨ë¸ í•™ìŠµ & í‰ê°€ (covid_exposure ê·¸ë£¹ë³„)
# --------------------------------------------------

print("â–¶ í›ˆë ¨ ê°€ëŠ¥ ë°ì´í„° í˜„í™©:")
print(f"- ì´ í–‰ ìˆ˜: {len(df)}")
print(f"- issue_d â‰¥ 2019-05-01: {len(df[df['issue_d'] >= '2015-01-01'])}")
print(f"- covid_exposure=0: {len(df[df['covid_exposure']==0])}")

# Removed the original loop over "early" and "late" subgroups for model training and SHAP calculation

from sklearn.utils import resample
import shap

print("\nğŸ” ì „ì²´ ë°ì´í„° ê¸°ë°˜ SHAP ë¶„ì„")
print(f"X shape: {X.shape}, df[['T', 'E']] shape: {df[['T', 'E']].shape}")
shap_runs = []
from collections import Counter
for i in range(10):  # bootstrap iterations
    X_bs, y_bs = resample(X, df[["T", "E"]], replace=True, random_state=42 + i)
    y_surv_bs = Surv.from_arrays(event=y_bs["E"].astype(bool), time=y_bs["T"])
    rsf = RandomSurvivalForest(n_estimators=100, min_samples_split=10,
                               min_samples_leaf=15, max_features="sqrt",
                               n_jobs=-1, random_state=42 + i)
    rsf.fit(X_bs, y_surv_bs)
    print(f"âœ… ë¶€íŠ¸ìŠ¤íŠ¸ë© {i+1}/10 í•™ìŠµ ì™„ë£Œ")
    shap_runs.append(rsf.feature_importances_)
    if i == 0:
        top_idx_list = []
    top_idx = np.argsort(rsf.feature_importances_)[::-1][:5]
    top_idx_list.extend(top_idx)

top_5_idx = [item[0] for item in Counter(top_idx_list).most_common(5)]
top_5_features = [features[i] for i in top_5_idx]
print(f"ğŸ” ì „ì²´ ê¸°ì¤€ Top 5 features:", top_5_features)

rsf_final = RandomSurvivalForest(n_estimators=100, min_samples_split=10,
                                 min_samples_leaf=15, max_features="sqrt",
                                 n_jobs=-1, random_state=999)
y_final = Surv.from_arrays(event=df["E"].astype(bool), time=df["T"])
rsf_final.fit(X, y_final)
print("âœ… ìµœì¢… RSF í•™ìŠµ ì™„ë£Œ")


    # Restrict X to top 5 features for SHAP computation
X_top5 = X[top_5_features].copy()

# â–¼â–¼â–¼ SHAP ê³„ì‚° ìµœì í™”ë¥¼ ìœ„í•œ ë‹¤ìš´ìƒ˜í”Œë§ (E ë¹„ìœ¨ ìœ ì§€) â–¼â–¼â–¼
from sklearn.model_selection import train_test_split

X_top5["T"] = df["T"]
X_top5["E"] = df["E"]

# Stratified downsampling to 20,000 rows maintaining event proportion
X_top5_sampled, _ = train_test_split(
    X_top5,
    train_size=20000,
    stratify=X_top5["E"],
    random_state=999
)

y_top5_sampled = Surv.from_arrays(
    event=X_top5_sampled["E"].astype(bool),
    time=X_top5_sampled["T"]
)

# Drop T, E from features for SHAP
X_top5_sampled = X_top5_sampled.drop(columns=["T", "E"])

explainer = shap.TreeExplainer(rsf_final)
shap_values = explainer.shap_values(X_top5_sampled)
print("âœ… SHAP ê³„ì‚° ì™„ë£Œ (ìƒ˜í”Œ 20,000ê±´ ê¸°ì¤€)")

df["issue_month"] = df["issue_d"].dt.to_period("M")
shap_df = pd.DataFrame(shap_values, columns=top_5_features)
shap_df["issue_month"] = df["issue_month"].values
mean_by_month = shap_df.groupby("issue_month")[top_5_features].mean()
print("âœ… ì›”ë³„ SHAP í‰ê· ê°’ ê³„ì‚° ì™„ë£Œ")
top_features_by_month = {"all": mean_by_month}

# ì €ì¥ ë˜ëŠ” ì‹œê°í™”ìš© ê²°ê³¼ ì¤€ë¹„ë¨

# --------------------------------------------------
# 6) í…ŒìŠ¤íŠ¸ ì„±ëŠ¥
# --------------------------------------------------
# (Removed CoxPHFitter test performance and variable selection saving as per instructions)

import matplotlib.pyplot as plt
import seaborn as sns

# ì‹œê°í™”: ì›”ë³„ top featureë“¤ì˜ SHAP í‰ê· ê°’ ì¶”ì´
monthly_df = top_features_by_month["all"]
plt.figure(figsize=(12, 6))
for col in monthly_df.columns:
    sns.lineplot(data=monthly_df[col], label=col)
plt.title(f"ì›”ë³„ SHAP í‰ê· ê°’ ì¶”ì´")
plt.xlabel("issue_month")
plt.ylabel("í‰ê·  SHAP ê°’")
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# ì‹œê°í™”: ê° ê·¸ë£¹ì—ì„œ top featureë“¤ì˜ SHAP ì´í•© ë¹„ì¤‘ (ë¹„ìœ¨ ê¸°ë°˜ ì¤‘ìš”ë„)
mean_abs = monthly_df.abs().sum()
mean_abs = mean_abs / mean_abs.sum()  # Normalize to sum=1
plt.figure(figsize=(6, 4))
sns.barplot(x=mean_abs.values, y=mean_abs.index)
plt.title(f"Top 5 ë³€ìˆ˜ SHAP ë¹„ì¤‘")
plt.xlabel("SHAP ë¹„ì¤‘")
plt.ylabel("ë³€ìˆ˜ëª…")
plt.tight_layout()
plt.show()